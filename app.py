import streamlit as st
import pandas as pd
import os
import sys

# Add current directory to path so we can import src modules
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src import data_manager, cleaner, model_engine, visualizer

st.set_page_config(page_title="Antigravity æ•¸æ“šè™•ç†æ¨¡çµ„", layout="wide")

# --- Auth Check ---
def check_password():
    """Returns `True` if the user had the correct password."""

    def password_entered():
        """Checks whether a password entered by the user is correct."""
        if st.session_state["password"] == st.secrets["app_password"]:
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # Don't store password
        else:
            st.session_state["password_correct"] = False

    # 1. Check if configured
    try:
        if "app_password" not in st.secrets:
            # No password set -> Open Access (or Warning)
            st.sidebar.warning("âš ï¸ æœªè¨­å®šå¯†ç¢¼ (app_password)ã€‚ç¶²ç«™ç›®å‰å…¬é–‹ã€‚")
            return True
            
    except Exception:
        # Local run without secrets.toml
        # st.sidebar.info("â„¹ï¸ æœ¬åœ°æ¨¡å¼ (ç„¡ secrets.toml)ï¼šç•¥éå¯†ç¢¼é©—è­‰ã€‚")
        return True

    # 2. Check session state
    if "password_correct" not in st.session_state:
        # First run, show input
        st.text_input(
            "è«‹è¼¸å…¥ç³»çµ±å¯†ç¢¼ (Password)", type="password", on_change=password_entered, key="password"
        )
        return False
    elif not st.session_state["password_correct"]:
        # Password incorrect, show input again
        st.text_input(
            "è«‹è¼¸å…¥ç³»çµ±å¯†ç¢¼ (Password)", type="password", on_change=password_entered, key="password"
        )
        st.error("ğŸ˜• å¯†ç¢¼éŒ¯èª¤")
        return False
    else:
        # Password correct
        return True

if not check_password():
    st.stop()

# --- Global Definitions ---
TYPE_MAPPING = {
    "ä¸ä½¿ç”¨ (Unused)": "Unused",
    "ID (è­˜åˆ¥ç¢¼)": "ID",
    "æ•¸å€¼ç‰¹å¾µ (Numerical)": "Numerical",
    "é¡åˆ¥ç‰¹å¾µ (Categorical)": "Categorical",
    "æ™‚é–“ç‰¹å¾µ (Datetime)": "Datetime",
    "é æ¸¬ç›®æ¨™ (Target)": "Target"
}
REVERSE_TYPE_MAPPING = {v: k for k, v in TYPE_MAPPING.items()}
OPTIONS_DISPLAY = list(TYPE_MAPPING.keys())

st.title("Antigravity æ™ºèƒ½é æ¸¬å¹³å° (AI Prediction Platform) ğŸš€")

# --- Sidebar Configuration ---
st.sidebar.header("ç³»çµ±è¨­å®š (Configuration)")
st.sidebar.text("Debug: Options loaded: " + str(len(OPTIONS_DISPLAY))) # Debug info
data_source_path = st.sidebar.text_input("è³‡æ–™ä¾†æºè·¯å¾‘ (Data Source Path)", value=data_manager.DATA_DIR)

st.sidebar.markdown("---")
st.sidebar.header("æ¨¡å‹ç‰ˆæœ¬ç®¡ç† (Model Versioning)")
if 'model_engine' not in st.session_state:
    st.session_state.model_engine = model_engine.ModelEngine()

available_models = st.session_state.model_engine.list_models()
if not available_models:
    model_options = ["å°šç„¡æ¨¡å‹ (No Models)"]
    selected_model_name = model_options[0]
else:
    model_options = available_models
    # Default to first (latest)
    selected_model_name = st.sidebar.selectbox("é¸æ“‡ä½¿ç”¨æ¨¡å‹ç‰ˆæœ¬", model_options)

# Auto-load logic
if 'current_model_name' not in st.session_state:
    st.session_state.current_model_name = None

if selected_model_name != "å°šç„¡æ¨¡å‹ (No Models)" and selected_model_name != st.session_state.current_model_name:
    # Load the model
    try:
        model_path = os.path.join(model_engine.MODEL_DIR, selected_model_name)
        st.session_state.current_model = st.session_state.model_engine.load_model(model_path)
        st.session_state.current_model_name = selected_model_name
        st.sidebar.success(f"å·²è¼‰å…¥: {selected_model_name}")
    except Exception as e:
        st.sidebar.error(f"è¼‰å…¥å¤±æ•—: {e}")

    except Exception as e:
        st.sidebar.error(f"è¼‰å…¥å¤±æ•—: {e}")

    except Exception as e:
        st.sidebar.error(f"è¼‰å…¥å¤±æ•—: {e}")

# --- Model Import/Export (Manual) ---
st.sidebar.markdown("---")
st.sidebar.header("æ¨¡å‹å­˜å– (Import/Export)")

# 1. Download Current Model
if st.session_state.current_model_name:
    local_path = os.path.join(model_engine.MODEL_DIR, st.session_state.current_model_name)
    if os.path.exists(local_path):
        with open(local_path, "rb") as f:
            st.sidebar.download_button(
                label="ğŸ“¥ ä¸‹è¼‰æ­¤æ¨¡å‹ (.joblib)",
                data=f,
                file_name=st.session_state.current_model_name,
                mime="application/octet-stream"
            )

# 2. Upload External Model
uploaded_model = st.sidebar.file_uploader("ğŸ“¤ ä¸Šå‚³èˆŠæ¨¡å‹ (Restore)", type=["joblib"], key="model_restore")
if uploaded_model:
    # Save to models directory
    restore_path = os.path.join(model_engine.MODEL_DIR, uploaded_model.name)
    with open(restore_path, "wb") as f:
        f.write(uploaded_model.getbuffer())
    
    st.sidebar.success(f"å·²é‚„åŸ: {uploaded_model.name}")
    
    # Reload functionality
    if st.sidebar.button("è¼‰å…¥æ­¤æ¨¡å‹ (Load Uploaded)"):
        try:
            st.session_state.current_model = st.session_state.model_engine.load_model(restore_path)
            st.session_state.current_model_name = uploaded_model.name
            st.rerun()
        except:
             st.sidebar.error("è¼‰å…¥å¤±æ•—ï¼Œæª”æ¡ˆå¯èƒ½ææ¯€")

st.sidebar.markdown("---")
st.sidebar.header("é¸æ“‡å·¥ä½œæµç¨‹ (Workflow)")
workflow = st.sidebar.selectbox(
    "è«‹é¸æ“‡ AI ä»»å‹™é¡å‹",
    [
        "1. ğŸ¯ ä¸‹å–®æ©Ÿç‡é æ¸¬ (Purchase Prediction)",
        "2. ğŸ‘¥ å®¢ç¾¤åˆ†ç¾¤åˆ†æ (Segmentation)",
        "3. ğŸ’° æ¶ˆè²»é‡‘é¡é æ¸¬ (Value Prediction)",
        "4. ğŸ•µï¸â€â™‚ï¸ æ½›åœ¨å®¢æˆ¶æŒ–æ˜ (PU Learning)"
    ]
)

# Initialize Session State
if 'df_raw' not in st.session_state:
    st.session_state.df_raw = None
# PU Learning needs two dataframes
if 'df_pos' not in st.session_state:
    st.session_state.df_pos = None
if 'df_unlabeled' not in st.session_state:
    st.session_state.df_unlabeled = None

if 'df_processed' not in st.session_state:
    st.session_state.df_processed = None
if 'metadata' not in st.session_state:
    st.session_state.metadata = {}
if 'model_engine' not in st.session_state:
    st.session_state.model_engine = model_engine.ModelEngine()
if 'current_model' not in st.session_state:
    st.session_state.current_model = None

# --- Main Interface ---
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "1. è³‡æ–™æº–å‚™ (Data Prep)", 
    "2. æ¨¡å‹è¨“ç·´ (Model Training)", 
    "3. é æ¸¬èˆ‡æ‡‰ç”¨ (Prediction)",
    "4. ä¿®æ­£èˆ‡å„ªåŒ– (Feedback)",
    "5. æˆ°æƒ…å„€è¡¨æ¿ (Dashboard)"
])

# === TAB 1: DATA PREP ===
with tab1:
    st.header("è³‡æ–™åŒ¯å…¥èˆ‡æ¬„ä½å®šç¾©")
    
    if "PU Learning" in workflow:
        st.info("ğŸ•µï¸â€â™‚ï¸ PU Learning éœ€è¦å…©ä»½è³‡æ–™ï¼šå·²è¢«æ¨™è¨˜çš„æ­£å‘åå–® (File A) èˆ‡ æœªæ¨™è¨˜åå–® (File B)")
        col_u1, col_u2 = st.columns(2)
        
        with col_u1:
            up_pos = st.file_uploader("ä¸Šå‚³æ­£å‘åå–® (File A - å·²è³¼å®¢)", type=["csv"], key="pu_pos")
            if up_pos:
                st.session_state.df_pos = data_manager.load_csv_robust(up_pos)
                st.success(f"å·²è¼‰å…¥æ­£å‘æ¨£æœ¬: {len(st.session_state.df_pos)} ç­†")
                
        with col_u2:
            up_un = st.file_uploader("ä¸Šå‚³æœªæ¨™è¨˜åå–® (File B - æ½›åœ¨å®¢)", type=["csv"], key="pu_un")
            if up_un:
                st.session_state.df_unlabeled = data_manager.load_csv_robust(up_un)
                st.success(f"å·²è¼‰å…¥æœªæ¨™è¨˜æ¨£æœ¬: {len(st.session_state.df_unlabeled)} ç­†")
        
        # Combine for metadata definition (taking mostly from B as it's the target space)
        # But we need to make sure columns match.
        if st.session_state.df_pos is not None and st.session_state.df_unlabeled is not None:
             # Concatenate for metadata view
             st.session_state.df_raw = pd.concat([st.session_state.df_pos, st.session_state.df_unlabeled], ignore_index=True)
    else:
        # Standard Single File Upload
        uploaded_file = st.file_uploader("ä¸Šå‚³è¨“ç·´è³‡æ–™ (CSV)", type=["csv"], key="train_uploader")
        if uploaded_file is not None:
            try:
                st.session_state.df_raw = data_manager.load_csv_robust(uploaded_file)
                st.success(f"æˆåŠŸè¼‰å…¥ {uploaded_file.name}ï¼Œè³‡æ–™å½¢ç‹€: {st.session_state.df_raw.shape}")
            except Exception as e:
                st.error(f"æª”æ¡ˆè®€å–å¤±æ•—: {e}")

    # Metadata Mapping Section
    if st.session_state.df_raw is not None:
        st.subheader("æ¬„ä½å±¬æ€§å®šç¾©")
        df = st.session_state.df_raw
        cols = df.columns.tolist()
        
        # Determine target logic defaults
        # If clustering, hide/disable Target option? Or just let user ignore it.
        # Let's keep it consistent but guide user with text.
        if "Segmentation" in workflow:
            st.info("â„¹ï¸ åˆ†ç¾¤åˆ†æç‚ºéç›£ç£å¼å­¸ç¿’ï¼Œä¸éœ€è¦è¨­å®šã€é æ¸¬ç›®æ¨™ (Target)ã€ã€‚")
        
        col1, col2 = st.columns(2)
        with col1:
            updated_metadata = {}
            for col in cols:
                current_backend_type = st.session_state.metadata.get(col, "Unused")
                default_display = REVERSE_TYPE_MAPPING.get(current_backend_type, "ä¸ä½¿ç”¨ (Unused)")
                
                try:
                    default_idx = OPTIONS_DISPLAY.index(default_display)
                except:
                    default_idx = 0
                
                selected_display = st.selectbox(f"'{col}' çš„å±¬æ€§", OPTIONS_DISPLAY, index=default_idx, key=f"sel_{col}")
                backend_type = TYPE_MAPPING[selected_display]
                
                if backend_type != "Unused":
                    updated_metadata[col] = backend_type
                    
        with col2:
            st.json(updated_metadata)
            if st.button("å„²å­˜æ¬„ä½è¨­å®š (Save Metadata)"):
                st.session_state.metadata = updated_metadata
                data_manager.save_metadata(updated_metadata)
                st.success("æ¬„ä½è¨­å®šå·²å„²å­˜ï¼")

        # Processing Section
        st.subheader("åŸ·è¡Œè³‡æ–™æ¸…æ´—")
        if st.button("æŒ‰ç…§è¨­å®šåŸ·è¡Œæ¸…æ´— (Run Cleaning)"):
             if not st.session_state.metadata:
                st.error("è«‹å…ˆå®šç¾©ä¸¦å„²å­˜æ¬„ä½è¨­å®šï¼")
             else:
                with st.spinner("è³‡æ–™æ¸…æ´—èˆ‡ç‰¹å¾µå·¥ç¨‹ä¸­..."):
                    options = {"batch_id": "manual_run"} # Default options for now, can expand later
                    try:
                        df_proc = cleaner.clean_data(st.session_state.df_raw, st.session_state.metadata, options)
                        st.session_state.df_processed = df_proc
                        data_manager.save_processed_data(df_proc)
                        st.success("æ¸…æ´—å®Œæˆï¼å¯å‰å¾€ã€æ¨¡å‹è¨“ç·´ã€åˆ†é ã€‚")
                        st.dataframe(df_proc.head())
                    except Exception as e:
                        st.error(f"è™•ç†å¤±æ•—: {e}")

# === TAB 2: MODEL TRAINING ===
with tab2:
    st.header(f"æ¨¡å‹è¨“ç·´: {workflow}")
    
    if st.session_state.df_processed is None:
        st.warning("è«‹å…ˆåœ¨ç¬¬ä¸€é å®Œæˆè³‡æ–™æº–å‚™ã€‚")
    else:
        df_train = st.session_state.df_processed
        
        # Identify special columns
        target_col = next((c for c, t in st.session_state.metadata.items() if t == 'Target'), None)
        id_col = next((c for c, t in st.session_state.metadata.items() if t == 'ID'), None)
        
        # UI Logic based on Workflow
        if "Purchase Prediction" in workflow:
            is_lookalike = st.checkbox("åƒ…åŒ…å«æ­£å‘æ¨£æœ¬ (ç´”ä¸‹å–®åå–® / Lookalike Modeling)", value=True, help="å¦‚æœæ‚¨çš„è¨“ç·´æª”æ¡ˆåªæœ‰ã€Œå·²ä¸‹å–®ã€çš„å®¢æˆ¶ï¼Œè«‹å‹¾é¸æ­¤é …ã€‚ç³»çµ±å°‡å°‹æ‰¾èˆ‡é€™ç¾¤äººç›¸ä¼¼çš„æ½›åœ¨å®¢æˆ¶ã€‚")
            
            if is_lookalike:
                st.info("æ¨¡å¼ï¼šç›¸ä¼¼å—çœ¾åˆ†æ (Lookalike)ã€‚ç³»çµ±å°‡å­¸ç¿’æ­¤åå–®çš„ç‰¹å¾µåˆ†ä½ˆï¼Œæ‰¾å‡ºé¡ä¼¼çš„æ½›åœ¨å®¢æˆ¶ã€‚")
                if st.button("é–‹å§‹è¨“ç·´ (Train Lookalike Model)"):
                    with st.spinner("è¨“ç·´æ½›åœ¨å—çœ¾æ¨¡å‹ä¸­..."):
                        engine = st.session_state.model_engine
                        # Lookalike doesn't use target column
                        model, metrics = engine.train_lookalike(df_train, id_col)
                        st.session_state.current_model = model
                        
                        st.success(f"è¨“ç·´å®Œæˆï¼å·²å­¸ç¿’ {metrics['num_samples']} ç­†æ­£å‘æ¨£æœ¬ã€‚")
                        
                         # Feature Importance (IsolationForest implies importance via split features, but sklearn doesn't provide it easily. Skiping plot or using simple variance?)
                        st.write("æ¨¡å‹å·²æº–å‚™å¥½é€²è¡Œåå–®é æ¸¬ã€‚è«‹å‰å¾€ç¬¬ä¸‰é ã€‚")
                        
                        # Save
                        path, name = engine.save_model(model, "lookalike")
                        st.info(f"æ¨¡å‹å·²å„²å­˜: {name}")

            else:
                # Standard Classification
                if not target_col:
                    st.error("æ¨™æº–åˆ†é¡æ¨¡å¼éœ€è¦å®šç¾©ã€é æ¸¬ç›®æ¨™ (Target)ã€æ¬„ä½ï¼è«‹å›ç¬¬ä¸€é è¨­å®šï¼Œæˆ–å‹¾é¸ä¸Šæ–¹ã€åƒ…åŒ…å«æ­£å‘æ¨£æœ¬ã€ã€‚")
                else:
                    st.write(f"é æ¸¬ç›®æ¨™: **{target_col}** (åˆ†é¡ä»»å‹™)")
                    if st.button("é–‹å§‹è¨“ç·´ (Train Classifier)"):
                        with st.spinner("è¨“ç·´ä¸­..."):
                            engine = st.session_state.model_engine
                            model, metrics = engine.train_classification(df_train, target_col, id_col)
                            st.session_state.current_model = model
                            
                            st.success("è¨“ç·´å®Œæˆï¼")
                            visualizer.plot_classification_metrics(metrics)
                            
                            # Feature Importance
                            feature_cols = [c for c in df_train.columns if c not in [target_col, id_col, 'Batch_ID']]
                            st.subheader("ç‰¹å¾µé‡è¦æ€§åˆ†æ (Feature Analysis)")
                            visualizer.plot_feature_importance(model, feature_cols)
                            
                            # Textual Explanation
                            insights = visualizer.explain_feature_importance(model, feature_cols)
                            for line in insights:
                                st.markdown(line)
                            
                            # Save
                            path, name = engine.save_model(model, "classifier")
                            st.info(f"æ¨¡å‹å·²å„²å­˜: {name}")

        elif "Segmentation" in workflow:
            st.write("åˆ†ç¾¤åˆ†æ (Clustering)")
            k_clusters = st.slider("é è¨ˆåˆ†ç¾¤æ•¸é‡ (K)", 2, 10, 3, help="å¦‚æœä¸çŸ¥é“é¸å¤šå°‘ï¼Œç³»çµ±æœƒè‡ªå‹•å˜—è©¦å°‹æ‰¾æœ€ä½³å€¼")
            auto_k = st.checkbox("è‡ªå‹•å°‹æ‰¾æœ€ä½³ K å€¼ (Auto K)", value=True)
            
            if st.button("åŸ·è¡Œåˆ†ç¾¤ (Run Clustering)"):
                with st.spinner("åˆ†ç¾¤é‹ç®—ä¸­..."):
                    engine = st.session_state.model_engine
                    k_arg = None if auto_k else k_clusters
                    model, metrics, labels = engine.train_clustering(df_train, id_col=id_col, k=k_arg)
                    st.session_state.current_model = model
                    
                    st.success(f"åˆ†ç¾¤å®Œæˆï¼æœ€ä½³ç¾¤æ•¸: {metrics['k']} (Silhouette: {metrics['silhouette_score']:.3f})")
                    
                    # Plotting
                    df_viz = df_train.copy()
                    df_viz['Cluster'] = labels
                    valid_cols = [c for c in df_viz.columns if pd.api.types.is_numeric_dtype(df_viz[c]) and c not in ['Cluster', 'Batch_ID']]
                    
                    visualizer.plot_clusters_2d(df_viz, 'Cluster', valid_cols)

        elif "PU Learning" in workflow:
            st.write("ğŸ•µï¸â€â™‚ï¸ æ½›åœ¨å®¢æˆ¶æŒ–æ˜ (Positive-Unlabeled Learning)")
            
            if st.session_state.df_pos is None or st.session_state.df_unlabeled is None:
                 st.error("è«‹å…ˆåœ¨ç¬¬ä¸€é ä¸Šå‚³ File A (æ­£å‘) èˆ‡ File B (æœªæ¨™è¨˜)ï¼")
            else:
                 # Manual Hints
                 st.info("æ­¤æ¨¡å‹æœƒè‡ªå‹•å€åˆ†æ­£å‘èˆ‡æœªæ¨™è¨˜è³‡æ–™ç‰¹å¾µã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰‹å‹•åŠ å¼·æŸäº›é—œéµç‰¹å¾µçš„æ¬Šé‡ã€‚")
                 
                 # Feature Weight Config
                 with st.expander("âš™ï¸ é€²éšè¨­å®šï¼šç‰¹å¾µåŠ æ¬Š (Feature Weights)"):
                     st.write("è¨­å®šæ¬Šé‡ (é è¨­ 1.0)ã€‚è¨­ç‚º 0 ä»£è¡¨è©²ç‰¹å¾µä¸åƒèˆ‡åŠ æ¬Šèª¿æ•´ã€‚")
                     feature_cols = [c for c in st.session_state.df_unlabeled.columns if c not in [id_col, 'Batch_ID']]
                     
                     weights = {}
                     cols = st.columns(3)
                     for i, col in enumerate(feature_cols):
                         with cols[i % 3]:
                             # Default 1.0
                             val = st.number_input(f"{col}", 0.0, 5.0, 1.0, 0.1, key=f"w_{col}")
                             if val != 1.0:
                                 weights[col] = val
                 
                 if st.button("é–‹å§‹æŒ–æ˜ (Train PU Model)"):
                     with st.spinner("æ­£åœ¨é€²è¡Œ PU Learning è¨“ç·´..."):
                         engine = st.session_state.model_engine
                         
                         # Need to pass separated DF A and B for cleaning?
                         # Usually we clean merged DF then split.
                         # Our Tab 1 merged them into df_raw and ran cleaner -> df_processed.
                         # Now we need to split df_processed back into Pos and Unlabeled based on index or source?
                         # Tricky.
                         # Easier approach: Clean df_pos and df_unlabeled SEPARATELY using same metadata options?
                         # Or just split df_processed.
                         
                         # Since df_raw was concat(pos, unlabeled), the first len(pos) rows are pos.
                         n_pos = len(st.session_state.df_pos)
                         df_proc = st.session_state.df_processed
                         
                         df_train_pos = df_proc.iloc[:n_pos].copy()
                         df_train_un = df_proc.iloc[n_pos:].copy()
                         
                         # Train
                         model, metrics = engine.train_pu_learning(df_train_pos, df_train_un, weights, id_col)
                         st.session_state.current_model = model
                         
                         st.success(f"è¨“ç·´å®Œæˆï¼AUC: {metrics['auc']:.4f}")
                         st.write(f"ä½¿ç”¨æ­£æ¨£æœ¬æ•¸: {metrics['pos_samples']}, è² æ¨£æœ¬æ•¸(æ¡æ¨£): {metrics['neg_samples_used']}")
                         
                         # Feature Importance (if pipeline)
                         # Extract from pipeline step 'clf' coefficients
                         # PU module handles this internally? 
                         # Let's try to extract coefficient info if available
                         try:
                             # Access inner pipeline
                             # model is CalibratedCV in app?
                             # engine returns (model, metrics)
                             # Wait, engine returns (calibrated_clf, metrics)
                             # We need the base estimator to get coefs.
                             # CalibratedClassifierCV -> calibrated_classifiers_[0].estimator (if prefit) or base_estimator
                             
                             # Actually engine.train_pu_learning returns (calibrated_clf, metrics)
                             # Getting feature importance from calibrated SVM/Logistic is hard visually.
                             pass
                         except:
                             pass
                         
                         # Save
                         path, name = engine.save_model(model, "pu_model")
                         st.info(f"æ¨¡å‹å·²å„²å­˜: {name}")

        elif "Value Prediction" in workflow:
            if not target_col:
                st.error("æ­¤æ¨¡å¼éœ€è¦å®šç¾©ã€é æ¸¬ç›®æ¨™ (Target)ã€æ¬„ä½ï¼")
            else:
                st.write(f"é æ¸¬ç›®æ¨™: **{target_col}** (å›æ­¸ä»»å‹™)")
                if st.button("é–‹å§‹è¨“ç·´ (Train Regressor)"):
                    with st.spinner("è¨“ç·´ä¸­..."):
                        engine = st.session_state.model_engine
                        model, metrics = engine.train_regression(df_train, target_col, id_col)
                        st.session_state.current_model = model
                        
                        st.success(f"è¨“ç·´å®Œæˆ! MSE: {metrics['mse']:.4f}, R2: {metrics['r2']:.4f}")
                        
                        feature_cols = [c for c in df_train.columns if c not in [target_col, id_col, 'Batch_ID']]
                        st.subheader("ç‰¹å¾µé‡è¦æ€§åˆ†æ (Feature Analysis)")
                        visualizer.plot_feature_importance(model, feature_cols)
                        
                        # Textual Explanation
                        insights = visualizer.explain_feature_importance(model, feature_cols)
                        for line in insights:
                            st.markdown(line)

# === TAB 3: PREDICTION (Mode B) ===
with tab3:
    st.header("æ‡‰ç”¨èˆ‡é æ¸¬ (File B)")
    
    if st.session_state.current_model is None:
        st.warning("è«‹å…ˆè¨“ç·´æ¨¡å‹æˆ–è¼‰å…¥å·²æœ‰æ¨¡å‹ã€‚")
    else:
        st.info("ä½¿ç”¨ç•¶å‰è¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œé æ¸¬ã€‚")
        upload_pred = st.file_uploader("ä¸Šå‚³é æ¸¬åå–® (File B)", type=["csv"], key="pred_uploader")
        
        if upload_pred:
            df_pred_raw = data_manager.load_csv_robust(upload_pred)
            
            if st.button("åŸ·è¡Œé æ¸¬ (Generate Predictions)"):
                # Ideally we need to run same cleaning/pipeline on prediction data.
                # For Phase 2 MVP, we assume user uploads pre-processed or we reuse clean options
                # This is a critical TODO: persist cleaning pipeline.
                # For now, let's just run simple cleaning using current metadata
                options = {"batch_id": "prediction_run"}
                try:
                    df_pred_clean = cleaner.clean_data(df_pred_raw, st.session_state.metadata, options)
                    
                    # Ensure we pass the ID column so it gets dropped before prediction
                    id_col = next((c for c, t in st.session_state.metadata.items() if t == 'ID'), None)
                    
                    engine = st.session_state.model_engine
                    preds, probs = engine.predict(st.session_state.current_model, df_pred_clean, id_col=id_col)
                    
                    df_result = df_pred_raw.copy() # Attach to original?
                    df_result['Predicted_Result'] = preds
                    if probs is not None:
                        df_result['Probability_Score'] = probs
                        
                    st.success("é æ¸¬å®Œæˆï¼")
                    st.dataframe(df_result.head())
                    
                    # Download
                    csv = df_result.to_csv(index=False).encode('utf-8-sig') # ensuring utf-8-sig for excel
                    st.download_button(
                        "ä¸‹è¼‰é æ¸¬çµæœ (Download CSV)",
                        csv,
                        "prediction_results.csv",
                        "text/csv",
                        key='download-csv'
                    )
                    
                except Exception as e:
                    st.error(f"é æ¸¬æµç¨‹éŒ¯èª¤: {e}")
                    st.warning("æç¤º: é æ¸¬åå–®çš„æ¬„ä½çµæ§‹å¿…é ˆèˆ‡è¨“ç·´è³‡æ–™ä¸€è‡´ã€‚å¦‚æœé‡åˆ° Feature mismatchï¼Œè«‹æª¢æŸ¥ã€ç·¨è™Ÿã€æ¬„ä½æ˜¯å¦å·²åœ¨ç¬¬ä¸€é æ­£ç¢ºè¨­å®šç‚º 'ID' (ID å±¬æ€§ä¸æœƒè¢«ç”¨ä½œç‰¹å¾µ)ã€‚")


# === TAB 4: FEEDBACK (Mode C) ===
with tab4:
    st.header("ä¿®æ­£èˆ‡å„ªåŒ– (Feedback Loop)")
    st.info("æ­¤æ­¥é©Ÿç”¨æ–¼å°‡ã€Œå¯¦éš›åŸ·è¡Œçµæœ (File C)ã€å›é¥‹çµ¦ AIï¼Œä»¥æŒçºŒå„ªåŒ–æ¨¡å‹æº–ç¢ºåº¦ã€‚")
    
    if st.session_state.current_model is None:
        st.warning("è«‹å…ˆæœ‰è¨“ç·´å¥½çš„æ¨¡å‹ (v1.0)ï¼Œæ‰èƒ½é€²è¡Œå„ªåŒ– (v1.1)ã€‚")
    else:
        upload_feedback = st.file_uploader("ä¸Šå‚³å¯¦éš›çµæœè³‡æ–™ (File C)", type=["csv"], key="feedback_uploader")
        
        if upload_feedback:
             try:
                 df_feedback_raw = data_manager.load_csv_robust(upload_feedback)
                 st.write("å›é¥‹è³‡æ–™é è¦½:", df_feedback_raw.head())
                 
                 if st.button("åŸ·è¡Œæ¨¡å‹å„ªåŒ– (Update Model)"):
                    with st.spinner("æ­£åœ¨æ ¹æ“šå›é¥‹è³‡æ–™é‡æ–°èª¿æ ¡æ¨¡å‹..."):
                        try:
                            # Process Feedback Data
                            options = {"batch_id": "feedback_run"}
                            df_feedback_clean = cleaner.clean_data(df_feedback_raw, st.session_state.metadata, options)
                            
                            id_col = next((c for c, t in st.session_state.metadata.items() if t == 'ID'), None)
                            target_col = next((c for c, t in st.session_state.metadata.items() if t == 'Target'), None)
                            
                            engine = st.session_state.model_engine
                            current_model = st.session_state.current_model
                            
                            # Determine type
                            if "PU Learning" in workflow:
                                model_type = "pu_learning"
                            elif isinstance(current_model, model_engine.IsolationForest):
                                model_type = "lookalike"
                            else:
                                model_type = "standard"
                            
                            new_model, metrics = engine.update_model(current_model, df_feedback_clean, target_col, id_col, model_type)
                            st.session_state.current_model = new_model
                            
                            st.success("æ¨¡å‹å„ªåŒ–å®Œæˆï¼ç‰ˆæœ¬å·²æ›´æ–°ã€‚")
                            if "mse" in metrics:
                                 st.write(f"æ–°æ¨¡å‹èª¤å·® (MSE): {metrics['mse']:.4f}")
                            elif "silhouette_score" in metrics:
                                 st.write(f"æ–°åˆ†ç¾¤åˆ†æ•¸: {metrics['silhouette_score']:.3f}")
                            elif "num_samples" in metrics:
                                 st.write(f"Lookalike æ¨¡å‹å·²æ“´å……ï¼Œç›®å‰å­¸ç¿’æ¨£æœ¬æ•¸: {metrics['num_samples']}")
                            else:
                                 visualizer.plot_classification_metrics(metrics)
                                 
                            # Save v1.1
                            path, name = engine.save_model(new_model, "model_v1.1")
                            st.info(f"å„ªåŒ–å¾Œæ¨¡å‹å·²å„²å­˜: {name}")
                            st.balloons()
                            
                        except NotImplementedError:
                            st.warning("âš ï¸ PU Learning å±¬æ–¼é«˜éšæ¨¡å‹ï¼Œå»ºè­°æ‚¨å°‡æ–°çš„è³¼è²·åå–®åˆä½µè‡³ã€æ­£å‘åå–® (File A)ã€å¾Œï¼Œå›åˆ°ç¬¬ä¸€é é‡æ–°ä¸Šå‚³ä¸¦é‡æ–°è¨“ç·´ï¼Œä»¥ç²å¾—æœ€ä½³æ•ˆæœã€‚")
                        except Exception as e:
                            st.error(f"å„ªåŒ–å¤±æ•—: {e}")
                            st.exception(e)
             except Exception as load_e:
                 st.error(f"è®€å–å¤±æ•—: {load_e}")


# === TAB 5: DASHBOARD ===
with tab5:
    st.header("æ•¸æ“šæˆ°æƒ…å„€è¡¨æ¿ (Analytics Dashboard)")
    
    # KPIs
    st.subheader("é—œéµæŒ‡æ¨™ (KPIs)")
    k1, k2, k3 = st.columns(3)
    
    # Calculating stats (Simplified for MVP - normally would query a DB or log file)
    # We use session state or just count current model properties
    total_models = len(available_models) if available_models else 0
    current_ver = selected_model_name if selected_model_name else "N/A"
    
    k1.metric("å¯ç”¨æ¨¡å‹ç‰ˆæœ¬æ•¸", total_models)
    k2.metric("ç•¶å‰ä½¿ç”¨ç‰ˆæœ¬", current_ver.split('_v')[1].split('.')[0] if '_v' in current_ver else "N/A")
    k3.metric("ç³»çµ±ç‹€æ…‹", "ğŸŸ¢ Online")
    
    st.markdown("---")
    
    col_a, col_b = st.columns(2)
    
    with col_a:
        st.subheader("è½‰æ›æ¼æ–—ç¯„ä¾‹ (Conversion Funnel)")
        # In a real app, we would track: Rows Uploaded -> Rows Predictied -> High Prob Rows -> Actual Orders
        # Here we mock it based on typical workflow or current session data
        current_rows = len(st.session_state.df_raw) if st.session_state.df_raw is not None else 0
        current_preds = 0 # Track if we predicted in session?
        
        # Mock Data for Visualization Demo
        funnel_data = {
            "1. æ½›åœ¨åå–® (File B)": 1000,
            "2. æœ‰æ•ˆè³‡æ–™ (Valid)": 950,
            "3. é æ¸¬é«˜æ½›åŠ› (High Prob)": 320,
            "4. å¯¦éš›è½‰æ› (Conversion)": 85
        }
        visualizer.plot_funnel(funnel_data)
        st.caption("*æ­¤åœ–è¡¨ç›®å‰ç‚ºç¯„ä¾‹æ•¸æ“šï¼Œæœªä¾†å°‡ä¸²æ¥å¯¦éš›æ­·å²ç´€éŒ„")

    with col_b:
        st.subheader("æ¨¡å‹æº–ç¢ºç‡è¶¨å‹¢ (Accuracy Trend)")
        # Mock Data: showing improvement over versions
        trend_data = pd.DataFrame([
            {"Version": "v1.0 (2/1)", "Metric": "F1-Score", "Score": 0.65},
            {"Version": "v1.0 (2/1)", "Metric": "Precision", "Score": 0.60},
            {"Version": "v1.1 (2/3)", "Metric": "F1-Score", "Score": 0.72},
            {"Version": "v1.1 (2/3)", "Metric": "Precision", "Score": 0.75},
            {"Version": "v1.2 (Today)", "Metric": "F1-Score", "Score": 0.78},
            {"Version": "v1.2 (Today)", "Metric": "Precision", "Score": 0.82},
        ])
        visualizer.plot_accuracy_trend(trend_data)
        st.caption("*æ­¤åœ–è¡¨ç‚ºæ¨¡æ“¬è¶¨å‹¢ï¼Œå±•ç¤ºæ¨¡å‹ç¶“ç”± Feedback Loop å„ªåŒ–å¾Œçš„æˆé•·è»Œè·¡")
